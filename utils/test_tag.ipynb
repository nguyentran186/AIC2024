{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe13c779-9a48-4165-a709-7b994974f194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "# Path to your binary file\n",
    "index_file_path = \"./../dict/faiss_index_file.bin\"\n",
    "\n",
    "# Load the index\n",
    "index = faiss.read_index(index_file_path)\n",
    "\n",
    "# Now you can use the index for search or further operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "070f24d4-87b8-4960-a6fd-47b9d66df30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "642a2f12-1071-4049-90ea-857df0a22334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "keyframes_dir = './../dict/context_encoded/frame_tags_encoded'\n",
    "all_keyframe_dict = dict()\n",
    "\n",
    "# Iterate through each data part\n",
    "for part in sorted(os.listdir(keyframes_dir)):\n",
    "    data_part = part.split('_')[-1]  # Extract data part like L01, L02\n",
    "    if data_part[0] == 'L':\n",
    "        data_part_path = f'{keyframes_dir}/{data_part}'\n",
    "        video_dirs = sorted(os.listdir(data_part_path))\n",
    "\n",
    "        # Iterate through each video directory\n",
    "        for video_dir in video_dirs:\n",
    "            if video_dir[0] != 'V':\n",
    "                continue\n",
    "            vid_dir = video_dir[0:4]\n",
    "            json_file_path = os.path.join(data_part_path, video_dir)\n",
    "\n",
    "            # Open and read the JSON file\n",
    "            with open(json_file_path, 'r') as json_file:\n",
    "                json_data = json.load(json_file)\n",
    "            \n",
    "            # Merge JSON data into the main dictionary\n",
    "            for frame, tags in json_data.items():\n",
    "                new_key = f'{data_part}_{vid_dir}_{frame}'  # Create a new key\n",
    "                all_keyframe_dict[new_key] = tags\n",
    "\n",
    "# Now all_keyframe_paths contains the merged data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70d2e77c-e131-46b1-9da6-cdb0de1c3a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_tag_vector(tag, model):\n",
    "    \"\"\"Get the vector for a single tag.\"\"\"\n",
    "    if tag in model:\n",
    "        return model[tag]\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)  # Return zero vector if tag not in model\n",
    "\n",
    "def embed_tags(tags, model):\n",
    "    \"\"\"Embed a set of tags into a single vector by averaging.\"\"\"\n",
    "    vectors = [get_tag_vector(tag, model) for tag in tags]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)  # Return zero vector if no tags\n",
    "\n",
    "# Create embeddings for each key\n",
    "embeddings = {key: embed_tags(tags, model) for key, tags in all_keyframe_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71089971-6aab-4af7-88b5-5f03a41ce7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tags(query_tags, model, index, embeddings, top_k=1):\n",
    "    \"\"\"Search for tags similar to the given query tags.\"\"\"\n",
    "    query_vector = embed_tags(query_tags, model)\n",
    "    query_vector = np.expand_dims(query_vector, axis=0).astype('float32')\n",
    "    \n",
    "    distances, indices = index.search(query_vector, top_k)\n",
    "    \n",
    "    results = []\n",
    "    for i in indices[0]:\n",
    "        key = list(embeddings.keys())[i]\n",
    "        results.append(key)\n",
    "    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f453841-8799-4c1d-92e8-fabc3452e761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results: ['L08_V001_008']\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query = {\"people\", \"father\", \"son\", \"christmas\"}\n",
    "results = search_tags(query, model, index, embeddings)\n",
    "print(\"Search results:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3595b796-8756-4f85-aae3-24c0a2b2ddee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = \"L03_V026_117\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7989f4aa-4347-49fa-a01a-422fee806083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L01_V001_005\n"
     ]
    }
   ],
   "source": [
    "print(list(embeddings.keys())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4515a5b-403a-4667-a844-fdcec9f3a36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a283d004-43b3-4977-99a6-6e34cded9a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
