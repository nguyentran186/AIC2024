{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adcb7bfd-c9f7-4ad4-8f25-5512bab88494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import module\n",
    "import os\n",
    "import open_clip\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import faiss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61a9bae2-5b22-4e65-bf6f-b87e7a05ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "# Path to your binary file\n",
    "index_file_path = \"./../dict/faiss_clipv2_cosine.bin\"\n",
    "\n",
    "# Load the index\n",
    "index = faiss.read_index(index_file_path)\n",
    "\n",
    "# Now you can use the index for search or further operations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a804de3e-0191-46bf-9555-4311d7f06abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "##### Load Model #####\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "model, _, preprocess = open_clip.create_model_and_transforms('ViT-L-14', device=device, pretrained='datacomp_xl_s13b_b90k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9179ac79-de6d-40fd-b36d-54a88b904f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/nguyen/.code/AIChallenge2023/utils'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25c03f86-2583-442e-a290-7299986518e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Base directories\n",
    "dataset_base_dir = './../data/keyframes/'\n",
    "npy_base_dir = './../data_extraction/CLIP_features/'\n",
    "\n",
    "# Initialize the mapping dictionary\n",
    "frame_to_feature_map = {}\n",
    "\n",
    "# Loop over each L0x directory\n",
    "for level_dir in sorted(os.listdir(dataset_base_dir)):\n",
    "    if level_dir.startswith('Keyframes_'):\n",
    "        level_id = level_dir.split('_')[1]  # Extract L0x\n",
    "        \n",
    "        # Loop over each video directory within the L0x directory\n",
    "        for video_dir in sorted(os.listdir(os.path.join(dataset_base_dir, level_dir))):\n",
    "            video_id = video_dir.split('_')[1]  # Extract V00y\n",
    "\n",
    "            # Load the features from the corresponding npy file\n",
    "            npy_file_path = os.path.join(npy_base_dir, level_id, f'{video_id}.npy')\n",
    "            if os.path.exists(npy_file_path):\n",
    "                features = np.load(npy_file_path)\n",
    "            else:\n",
    "                print(f\"Warning: Missing npy file for {level_id}_{video_id}\")\n",
    "                continue\n",
    "\n",
    "            # Get the list of frames in the video directory\n",
    "            frame_files = sorted(os.listdir(os.path.join(dataset_base_dir, level_dir, video_dir)))\n",
    "\n",
    "            # Map each frame to its corresponding feature\n",
    "            for i, frame_file in enumerate(frame_files):\n",
    "                if frame_file.endswith('.jpg'):\n",
    "                    frame_index = os.path.splitext(frame_file)[0]\n",
    "                    key = f\"{level_id}_{video_id}_{frame_index}\"\n",
    "                    frame_to_feature_map[key] = features[i].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9fa01360-0ba6-4c05-a6dc-06843d2ecb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tags(query_tags, model, index, embeddings, top_k=5):\n",
    "    \"\"\"Search for tags similar to the given query tags.\"\"\"\n",
    "    text_tokens = open_clip.tokenize(query_tags).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_features = model.encode_text(text_tokens)\n",
    "\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    text_features = text_features.cpu().detach().numpy().astype(np.float32)\n",
    "    \n",
    "    distances, indices = index.search(text_features, top_k)\n",
    "\n",
    "    scores, idx_image = index.search(text_features, k=top_k)\n",
    "\n",
    "    idx_image = idx_image.flatten()\n",
    "    \n",
    "    results = []\n",
    "    for i in indices[0]:\n",
    "        key = list(embeddings.keys())[i]\n",
    "        results.append(key)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "988a03dc-2bd9-47c8-9516-3a32978e1957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query\n",
    "query = [\"A man with g jacket\"]\n",
    "results = search_tags(query, model, index, frame_to_feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bcf46fe9-8a74-4480-b967-86cea4a06075",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'L08_V001_139' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mL08_V001_139\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'L08_V001_139' is not defined"
     ]
    }
   ],
   "source": [
    "vid = \"L0_V026_117\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1de145ab-66c9-4082-9fbe-eebbcf2ab414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(results.index(vid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cde6a1cc-f8db-4bf9-8561-42568d5289b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['L11_V018_222', 'L07_V025_186', 'L11_V018_219', 'L07_V011_267', 'L06_V001_193']\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9372d17e-ab29-418e-bae2-ced89788d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = index.reconstruct(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "810b9780-dfa3-45bb-9b95-d935501516b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m scores, idx_image \u001b[38;5;241m=\u001b[39m \u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/faiss/class_wrappers.py:327\u001b[0m, in \u001b[0;36mhandle_Index.<locals>.replacement_search\u001b[0;34m(self, x, k, params, D, I)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreplacement_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, k, \u001b[38;5;241m*\u001b[39m, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, D\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, I\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    301\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Find the k nearest neighbors of the set of vectors x in the index.\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \n\u001b[1;32m    303\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m        When not enough results are found, the label is set to -1\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 327\u001b[0m     n, d \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    328\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(x, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "scores, idx_image = index.search(vector, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13681248-9e16-420f-8705-c0a90bd177cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L01_V001_005\n"
     ]
    }
   ],
   "source": [
    "print(list(frame_to_feature_map.keys())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0ce037-2426-4003-b3d8-6457cfe39a62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
